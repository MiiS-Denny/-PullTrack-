import io
import os
import re
import hmac
from collections import Counter, defaultdict
from datetime import datetime

import streamlit as st
from openpyxl import load_workbook
from openpyxl.styles import Font, PatternFill, Border, Alignment, Protection
from openpyxl.chart import Reference
from hashlib import pbkdf2_hmac

# ---- æ™‚å€ ----
try:
    from zoneinfo import ZoneInfo
    TZ = ZoneInfo("Asia/Taipei")
except Exception:
    TZ = None

SHEET_NAME = "Data"
FIXED_BASE = "XbarAndRchart"  # æª”åå›ºå®š base

# ---- é›œæ¹Šå¸³å¯†ï¼ˆå¯æ”¹ç”¨ st.secretsï¼‰----
PWD_DB = {
    "Charles": {"algo": "pbkdf2_sha256", "iter": 200000, "salt": "32ae892164a22af5f83261bd239ed304", "hash": "27fb5fb7bbe2629d8c53dbbdf021423cdb4e7015e5858deafb3a0e405139bb40"},
    "Hsiang":  {"algo": "pbkdf2_sha256", "iter": 200000, "salt": "9c31cdf98b82aa1741154680e456e3e0", "hash": "292e30442d243ea5f82879f1ce71f9ff2dc600f7234a075ba3ee130f45eb29b4"},
    "Sandy":   {"algo": "pbkdf2_sha256", "iter": 200000, "salt": "dd8fbb2a735b076e5cff3bdee67fc3cf", "hash": "7bff0a1388c1447e934552175786d2fa5b9bc9b17ac3d9da246182dd7ec31e35"},
    "Min":     {"algo": "pbkdf2_sha256", "iter": 200000, "salt": "a4a89474d39a1d89ac652a56ccd33301", "hash": "7d788d76be27923209c08aba44fdfc0ca6ce5530ed4b91283810fd0c34bc1a0f"},
    "May":     {"algo": "pbkdf2_sha256", "iter": 200000, "salt": "88d33f6eb3d9a6506b705c3810e7be0b", "hash": "53765f6d56af8c2e49f917c89d60212ab8aeec28d215c9e53cf394e897782631"},
    "Ping":    {"algo": "pbkdf2_sha256", "iter": 200000, "salt": "4af5ee4403ad13cb6a2b0836da5d02b1", "hash": "1c1757b927959d2ef8897467f1c823753ec166f0d5c0a1a8ed5d91a84f2ab00d"},
    "Denny":   {"algo": "pbkdf2_sha256", "iter": 200000, "salt": "bc88ba930b619a25dcce81e6ee616305", "hash": "3dfe81a7dd31acaf2816604c000637f328049d1ca9f13940e217ec51f3a5e7c7"},
    "Davina":  {"algo": "pbkdf2_sha256", "iter": 200000, "salt": "8ce1cb7106316a21db1b48534d7d1833", "hash": "3a79b1feaa96cd7dc7dbced0bc2226d84da22ecda5a38d7d44a58f98e8c24b96"},
    # å¦‚æœä½ å·²åŠ å…¥ Arthurï¼Œä¿æŒæ—¢æœ‰è¨­å®š
    "Arthur": {"algo": "pbkdf2_sha256", "iter": 200000, "salt": "8e9a0b3e6c6dd1dccd6964101b5af752", "hash": "0409292dedb20de507c7fae67d25f502998c80cb4fcace6758d8fedc042d5570"},

}

def verify_password(username: str, password: str) -> bool:
    rec = PWD_DB.get(username)
    if not rec or rec.get("algo") != "pbkdf2_sha256":
        return False
    salt = bytes.fromhex(rec["salt"])
    digest = pbkdf2_hmac("sha256", password.encode("utf-8"), salt, rec["iter"], dklen=32)
    return hmac.compare_digest(digest, bytes.fromhex(rec["hash"]))

# ---- Excel å·¥å…· ----
COL_DATE = 1; COL_V_START = 2; COL_V_END = 7
COL_XBAR = 8; COL_R = 9
COL_CL_XBAR = 10; COL_UCL_XBAR = 11; COL_LCL_XBAR = 12
COL_CL_R = 13; COL_UCL_R = 14; COL_LCL_R = 15
COL_OWNER = 16

def find_last_data_row(ws, col=COL_DATE):
    for r in range(ws.max_row, 1, -1):
        v = ws.cell(row=r, column=col).value
        if v not in (None, ""):
            return r
    return 1

def validate_yyyymmdd(s: str) -> bool:
    return bool(re.fullmatch(r"\d{8}", s or ""))

def to_float_or_raise(s: str, name: str) -> float:
    try:
        return float(s)
    except Exception:
        raise ValueError(f"{name} éœ€ç‚ºæ•¸å­—ï¼Œæ”¶åˆ°ï¼š{s!r}")

def copy_cell_style(src, dst):
    if src.has_style:
        if src.font:        dst.font = Font(**src.font.__dict__)
        if src.alignment:   dst.alignment = Alignment(**src.alignment.__dict__)
        if src.border:      dst.border = Border(**src.border.__dict__)
        if src.fill:        dst.fill = PatternFill(**src.fill.__dict__)
        if src.protection:  dst.protection = Protection(**src.protection.__dict__)
        dst.number_format = src.number_format

def copy_row_styles(ws, from_row: int, to_row: int, col_start: int, col_end: int):
    ws.row_dimensions[to_row].height = ws.row_dimensions[from_row].height
    for c in range(col_start, col_end + 1):
        copy_cell_style(ws.cell(row=from_row, column=c), ws.cell(row=to_row, column=c))

def _reset_chart_series_to_cols(ws, chart, cols, last_row):
    anchor = getattr(chart, "anchor", None)
    title = getattr(chart, "title", None)
    y_title = getattr(getattr(chart, "y_axis", None), "title", None)
    chart.series = []
    cats = Reference(ws, min_col=COL_DATE, min_row=2, max_row=last_row)
    for col in cols:
        data = Reference(ws, min_col=col, min_row=1, max_row=last_row)
        chart.add_data(data, titles_from_data=True)
    chart.set_categories(cats)
    chart.title = title
    if hasattr(chart, "y_axis") and y_title is not None:
        chart.y_axis.title = y_title
    if anchor:
        chart.anchor = anchor

def refresh_existing_two_charts(ws, last_row):
    charts = getattr(ws, "_charts", [])
    if not charts: return
    _reset_chart_series_to_cols(ws, charts[0], (COL_XBAR, COL_CL_XBAR, COL_UCL_XBAR, COL_LCL_XBAR), last_row)
    if len(charts) >= 2:
        _reset_chart_series_to_cols(ws, charts[1], (COL_R, COL_CL_R, COL_UCL_R, COL_LCL_R), last_row)

def normalize_value_to_yyyymmdd(v) -> str | None:
    """æŠŠä»»æ„å„²å­˜æ ¼å€¼è½‰æˆ YYYYMMDDï¼›å…è¨±çµå°¾ -N ä¾‹å¦‚ 20251003-2ã€‚ç„¡æ³•åˆ¤è®€å‰‡å› Noneã€‚"""
    if v is None or v == "":
        return None
    if isinstance(v, datetime):
        return v.strftime("%Y%m%d")
    s = str(v).strip()
    # å…è¨± YYYYMMDD æˆ– YYYYMMDD-åºè™Ÿ
    m = re.fullmatch(r"(\d{8})(?:-(\d+))?", s)
    if m:
        return m.group(1)
    # ä¹Ÿå…è¨± YYYY-MM-DD / YYYY/MM/DD / YYYY.MM.DD ç­‰
    m = re.fullmatch(r"(\d{4})[-/\.]?(\d{1,2})[-/\.]?(\d{1,2})", s)
    if m:
        y, mo, d = m.groups()
        return f"{int(y):04d}{int(mo):02d}{int(d):02d}"
    return None

def read_last_date_str_from_wb(wb, sheet_name=SHEET_NAME) -> str:
    if sheet_name not in wb.sheetnames: return ""
    ws = wb[sheet_name]
    r = find_last_data_row(ws, col=COL_DATE)
    if r <= 1: return ""
    v = ws.cell(row=r, column=COL_DATE).value
    ymd = normalize_value_to_yyyymmdd(v)
    return ymd or ""

def read_all_dates_from_ws(ws) -> list[str]:
    """è®€å– A æ¬„æ‰€æœ‰æœ‰æ•ˆæ—¥æœŸï¼ˆç¬¬ 2 åˆ—èµ·ï¼‰ï¼Œå›å‚³ YYYYMMDD å­—ä¸²ä¸²åˆ—ï¼ˆå¯èƒ½é‡è¤‡ï¼‰ã€‚"""
    last = find_last_data_row(ws, col=COL_DATE)
    dates = []
    for r in range(2, last + 1):
        ymd = normalize_value_to_yyyymmdd(ws.cell(row=r, column=COL_DATE).value)
        if ymd:
            dates.append(ymd)
    return dates

def _append_one(ws, date_str: str, values: list[float], owner_text: str, seq_for_same_day: int | None):
    """seq_for_same_day: è‹¥ç‚º 1,2,3... å‰‡åœ¨ A æ¬„å¯« YYYYMMDD-1 / -2 / ...ï¼›None å‰‡å¯« YYYYMMDD"""
    last_row = find_last_data_row(ws, col=COL_DATE)
    new_row = last_row + 1
    copy_row_styles(ws, from_row=last_row, to_row=new_row, col_start=COL_DATE, col_end=COL_LCL_R)

    if seq_for_same_day is None:
        ws.cell(row=new_row, column=COL_DATE).value = str(date_str)
    else:
        ws.cell(row=new_row, column=COL_DATE).value = f"{date_str}-{seq_for_same_day}"

    for i, col in enumerate(range(COL_V_START, COL_V_END + 1), start=1):
        ws.cell(row=new_row, column=col).value = values[i-1]

    v_start = ws.cell(row=new_row, column=COL_V_START).coordinate
    v_end   = ws.cell(row=new_row, column=COL_V_END).coordinate
    ws.cell(row=new_row, column=COL_XBAR).value = f"=AVERAGE({v_start}:{v_end})"
    ws.cell(row=new_row, column=COL_R).value    = f"=MAX({v_start}:{v_end})-MIN({v_start}:{v_end})"

    if last_row >= 2:
        for col in (COL_CL_XBAR, COL_UCL_XBAR, COL_LCL_XBAR, COL_CL_R, COL_UCL_R, COL_LCL_R):
            ws.cell(row=new_row, column=col).value = ws.cell(row=last_row, column=col).value

    pcell = ws.cell(row=new_row, column=COL_OWNER)
    pcell.value = owner_text or ""
    pcell.font = Font(name="Calibri", size=11)
    return new_row

def append_many_bytes(template_bytes: bytes, rows_to_add: list, template_name: str, sheet_name=SHEET_NAME,
                      allow_same_day_multi: bool = False, same_day_dates_confirmed: set[str] | None = None):
    """
    å›å‚³ï¼š(last_used_date_for_name:str, out_bytes:bytes, reorder_info:dict)
    - è‹¥ allow_same_day_multi=Falseï¼Œé‡åˆ°èˆ‡æœ¬æ¬¡è¼¸å…¥å½¼æ­¤æˆ–èˆ‡ç¯„æœ¬é‡è¤‡çš„æ—¥æœŸæœƒ raise
    - è‹¥ allow_same_day_multi=Trueï¼Œå…è¨±åŒæ—¥å¤šç­†ï¼Œä¸¦å°‡åŒæ—¥çš„åˆ—åœ¨ A æ¬„æ¨™ç¤ºç‚º YYYYMMDD-1, -2, ...
      * åƒ…é‡å° 'same_day_dates_confirmed' å…§çš„æ—¥æœŸåŠ  -1/-2ï¼Œå…¶ä»–ä»ç¶­æŒ YYYYMMDD
    """
    wb = load_workbook(io.BytesIO(template_bytes), data_only=False)
    if sheet_name not in wb.sheetnames:
        wb.close()
        raise RuntimeError(f"æ‰¾ä¸åˆ°å·¥ä½œè¡¨ï¼š{sheet_name}")
    ws = wb[sheet_name]

    # è®€å–ç¯„æœ¬è³‡è¨Š
    wb_last_date_str = read_last_date_str_from_wb(wb, sheet_name)
    wb_last_date_int = int(wb_last_date_str) if wb_last_date_str.isdigit() else None
    existing_dates_list = read_all_dates_from_ws(ws)  # A æ¬„æ‰€æœ‰å·²å­˜åœ¨æ—¥æœŸï¼ˆYYYYMMDDï¼Œå¯é‡è¤‡ï¼‰
    existing_dates_set = set(existing_dates_list)

    # æ”¶é›†æœ¬æ¬¡æœ‰å¡«æ—¥æœŸçš„åˆ—
    collected = []
    original_order = []
    for idx, row in enumerate(rows_to_add, start=1):
        date_str = (row.get("date") or "").strip()
        if not date_str:
            continue
        if not validate_yyyymmdd(date_str):
            wb.close()
            raise ValueError(f"ç¬¬ {idx} åˆ—ï¼šæ—¥æœŸéœ€ç‚º YYYYMMDDï¼Œæ”¶åˆ° {date_str!r}")
        vals = row.get("values") or []
        if len(vals) != 6:
            wb.close()
            raise ValueError(f"ç¬¬ {idx} åˆ—ï¼šValue_1~Value_6 å¿…é ˆ 6 å€‹æ•¸å­—")
        nums = [to_float_or_raise(v, f"ç¬¬ {idx} åˆ— Value_{i+1}") for i, v in enumerate(vals)]
        owner = (row.get("owner") or "").strip()
        collected.append({"date": date_str, "values": nums, "owner": owner, "orig_idx": idx})
        original_order.append(date_str)

    if not collected:
        wb.close()
        raise ValueError("æ²’æœ‰å¯æ–°å¢çš„è³‡æ–™ï¼š12 åˆ—è¼¸å…¥ä¸­çš„æ—¥æœŸå…¨ç‚ºç©ºç™½")

    # 1) æª¢æŸ¥ï¼šæœ¬æ¬¡è¼¸å…¥å½¼æ­¤æ˜¯å¦æœ‰é‡è¤‡
    cnt = Counter([r["date"] for r in collected])
    dups_input = sorted([d for d, n in cnt.items() if n > 1])

    # 2) æª¢æŸ¥ï¼šæ˜¯å¦èˆ‡ç¯„æœ¬æ—¢æœ‰æ—¥æœŸé‡è¤‡
    dups_with_wb = sorted([d for d in cnt.keys() if d in existing_dates_set])

    # è‹¥ä¸å…è¨±åŒæ—¥å¤šç­†ï¼Œä¸”åµæ¸¬åˆ°é‡è¤‡ï¼Œç›´æ¥æ“‹ä¸‹
    need_confirm = bool(dups_input or dups_with_wb)
    if need_confirm and not allow_same_day_multi:
        wb.close()
        # ç”¨çµ±ä¸€è¨Šæ¯æŒ‡å‡ºå¯èƒ½çš„å…©ç¨®é‡è¤‡ä¾†æº
        msg_lines = []
        if dups_input:
            msg_lines.append("ãƒ»æœ¬æ¬¡è¼¸å…¥å½¼æ­¤é‡è¤‡ï¼š " + ", ".join(dups_input))
        if dups_with_wb:
            msg_lines.append("ãƒ»èˆ‡ç¯„æœ¬å…§æ—¢æœ‰æ—¥æœŸé‡è¤‡ï¼š " + ", ".join(dups_with_wb))
        raise ValueError("åµæ¸¬åˆ°åŒæ—¥å¤šç­†è³‡æ–™ã€‚\n" + "\n".join(msg_lines))

    # è‡ªå‹•æ’åºï¼ˆç”±å°åˆ°å¤§ï¼‰
    sorted_rows = sorted(collected, key=lambda r: int(r["date"]))
    sorted_order = [r["date"] for r in sorted_rows]
    was_reordered = (sorted_order != original_order)

    # åµæ¸¬æ˜¯å¦æœ‰æ—¥æœŸæ—©æ–¼ç¯„æœ¬æœ€å¾Œä¸€ç­†æ—¥æœŸï¼ˆåƒ…æç¤ºï¼Œä¸æ“‹ï¼‰
    has_earlier_than_wb = False
    if wb_last_date_int is not None:
        if any(int(r["date"]) < wb_last_date_int for r in sorted_rows):
            has_earlier_than_wb = True

    # å¯«å…¥ï¼ˆç”¨æ’åºå¾Œçš„é †åºï¼‰
    last_used_date_for_name = None

    # æ±ºå®šå“ªäº›æ—¥æœŸéœ€è¦åŠ  -1/-2ï¼ˆåªå°è¢«ä½¿ç”¨è€…ã€Œç¢ºèªè¦å¤šç­†ã€çš„æ—¥æœŸåšæ¨™è¨»ï¼‰
    confirmed_set = set(same_day_dates_confirmed or [])

    # è¨ˆç®—æœ¬æ¬¡æ‰¹æ¬¡å…§å°æ–¼æ¯ä¸€å€‹ã€Œéœ€æ¨™è¨»çš„æ—¥æœŸã€çš„åºè™Ÿ
    per_date_running_idx = defaultdict(int)

    for item in sorted_rows:
        d = item["date"]
        seq = None
        if d in confirmed_set:
            per_date_running_idx[d] += 1
            seq = per_date_running_idx[d]  # 1,2,3...
        _append_one(ws, d, item["values"], item["owner"], seq_for_same_day=seq)
        last_used_date_for_name = d

    # æ›´æ–°åœ–è¡¨è³‡æ–™ç¯„åœ
    last_row_after = find_last_data_row(ws, col=COL_DATE)
    refresh_existing_two_charts(ws, last_row_after)

    # è¼¸å‡º bytes
    out_io = io.BytesIO()
    wb.save(out_io); wb.close()
    out_bytes = out_io.getvalue()

    reorder_info = {
        "original_order": original_order,
        "sorted_order": sorted_order,
        "was_reordered": was_reordered,
        "wb_last_date": wb_last_date_str,
        "has_earlier_than_wb": has_earlier_than_wb,
        "dups_input": dups_input,
        "dups_with_wb": dups_with_wb,
        "confirmed_dates": sorted(list(confirmed_set)),
    }
    return last_used_date_for_name, out_bytes, reorder_info

# ---------------- Streamlit ä»‹é¢ ----------------
st.set_page_config(page_title="æ‹‰åŠ›å€¼ç´€éŒ„ï¼ˆé›²ç«¯ç‰ˆï¼‰", layout="wide")
st.title("æ‹‰åŠ›å€¼ç´€éŒ„ï¼ˆé›²ç«¯ç‰ˆï¼‰")

# Session ç‹€æ…‹
if "user" not in st.session_state: st.session_state.user = None
if "seq" not in st.session_state: st.session_state.seq = {}        # prefix -> int
if "last_result" not in st.session_state: st.session_state.last_result = None
if "last_reorder_info" not in st.session_state: st.session_state.last_reorder_info = None
if "login_user" not in st.session_state: st.session_state.login_user = list(PWD_DB.keys())[0]
if "login_pwd" not in st.session_state: st.session_state.login_pwd = ""
if "login_error" not in st.session_state: st.session_state.login_error = ""

# æ–°å¢ï¼šç”¨æ–¼ã€ŒåŒæ—¥å¤šç­†ã€çš„äº’å‹•æµç¨‹
if "pending_dups" not in st.session_state: st.session_state.pending_dups = None  # dict å­˜å¾…ç¢ºèªè³‡è¨Š
if "dup_confirmed" not in st.session_state: st.session_state.dup_confirmed = False

# ---- ç™»å…¥ï¼ˆé formï¼›Enter ä¸€æ¬¡å°±é€²ï¼‰----
def attempt_login():
    u = st.session_state.login_user
    p = st.session_state.login_pwd
    if verify_password(u, p):
        st.session_state.user = u
        st.session_state.login_error = ""
        st.rerun()
    else:
        st.session_state.login_error = "å¸³è™Ÿæˆ–å¯†ç¢¼éŒ¯èª¤ã€‚"

if st.session_state.user is None:
    st.subheader("ç™»å…¥")
    c1, c2, c3 = st.columns([2, 3, 1.2])
    with c1:
        st.selectbox("å¸³è™Ÿ", options=list(PWD_DB.keys()), key="login_user")
    with c2:
        st.text_input("å¯†ç¢¼", type="password", key="login_pwd", on_change=attempt_login)
    with c3:
        st.write("")
        st.button("ç™»å…¥", on_click=attempt_login, type="primary", use_container_width=True)
    if st.session_state.login_error:
        st.error(st.session_state.login_error)
    st.stop()

# ---- ç™»å‡ºåˆ— ----
logout_col, user_col = st.columns([1, 9])
with logout_col:
    if st.button("ç™»å‡º"):
        st.session_state.user = None
        st.rerun()
with user_col:
    st.write(f"ğŸ‘‹ å·²ç™»å…¥ï¼š**{st.session_state.user}**")

st.markdown("---")

# ---- ä¸Šå‚³ Excel ----
st.subheader("â‘  ä¸Šå‚³ Excel ç¯„æœ¬ï¼ˆéœ€åŒ…å«å·¥ä½œè¡¨ Data èˆ‡å…©å¼µåœ–è¡¨ï¼‰")
tpl_file = st.file_uploader("ä¸Šå‚³ .xlsx", type=["xlsx"])

# é è¦½æœ€å¾Œä¸€ç­†æ—¥æœŸ
last_date_placeholder = st.empty()
if tpl_file:
    try:
        wb_preview = load_workbook(tpl_file, data_only=True, read_only=True)
        last_str = read_last_date_str_from_wb(wb_preview, SHEET_NAME)
        wb_preview.close()
        if last_str: last_date_placeholder.info(f"ğŸ“Œ ç¯„æœ¬ç›®å‰æœ€å¾Œä¸€ç­†æ—¥æœŸï¼š**{last_str}**")
        else:        last_date_placeholder.warning("ç¯„æœ¬å…§å°šç„¡æœ‰æ•ˆè³‡æ–™æˆ–è®€ä¸åˆ°æ—¥æœŸã€‚")
    except Exception as e:
        last_date_placeholder.error(f"è®€å–ç¯„æœ¬å¤±æ•—ï¼š{e}")

st.markdown("---")

# ---- è¼¸å…¥è¡¨å–®ï¼ˆä¸‹è¼‰éˆ•åœ¨è¡¨å–®å¤–ï¼‰----
with st.form("input_form"):
    st.subheader("â‘¡ è¼¸å…¥è³‡æ–™ï¼ˆä¸€æ¬¡æœ€å¤š 12 åˆ—ï¼›ç©ºç™½æ—¥æœŸåˆ—è‡ªå‹•ç•¥éï¼‰")
    headers = ["Date(YYYYMMDD)", "Value_1(P1-1)", "Value_2(P1-2)", "Value_3(P1-3)",
               "Value_4(P2-1)", "Value_5(P2-2)", "Value_6(P2-3)"]

    rows = []
    for r in range(12):
        c1, c2, c3, c4, c5, c6, c7 = st.columns([1.2, 1, 1, 1, 1, 1, 1])
        with c1: d = st.text_input(f"{headers[0]} #{r+1}", value="", placeholder="YYYYMMDD", key=f"d_{r}")
        with c2: v1 = st.text_input(f"{headers[1]} #{r+1}", value="", key=f"v1_{r}")
        with c3: v2 = st.text_input(f"{headers[2]} #{r+1}", value="", key=f"v2_{r}")
        with c4: v3 = st.text_input(f"{headers[3]} #{r+1}", value="", key=f"v3_{r}")
        with c5: v4 = st.text_input(f"{headers[4]} #{r+1}", value="", key=f"v4_{r}")
        with c6: v5 = st.text_input(f"{headers[5]} #{r+1}", value="", key=f"v5_{r}")
        with c7: v6 = st.text_input(f"{headers[6]} #{r+1}", value="", key=f"v6_{r}")
        rows.append({"date": d.strip(), "values": [v1.strip(), v2.strip(), v3.strip(), v4.strip(), v5.strip(), v6.strip()], "owner": st.session_state.user})

    submitted = st.form_submit_button("â‘¢ é€å‡ºï¼ˆç”Ÿæˆä¸‹è¼‰æª”ï¼‰", type="primary", use_container_width=True)

    if submitted:
        if not tpl_file:
            st.error("è«‹å…ˆä¸Šå‚³ Excel ç¯„æœ¬ï¼ˆ.xlsxï¼‰ã€‚")
        else:
            # ç¬¬ä¸€æ¬¡é€å‡ºï¼šå…ˆå˜—è©¦ä¸å…è¨±åŒæ—¥å¤šç­†ï¼Œè‹¥åµæ¸¬åˆ°é‡è¤‡ï¼Œæ”¹ç”¨ã€Œäº’å‹•ç¢ºèªã€æµç¨‹
            try:
                # å…ˆåªåšæª¢æŸ¥ï¼Œä¸å…è¨±åŒæ—¥å¤šç­†ï¼ˆé‡åˆ°é‡è¤‡æœƒ raiseï¼‰
                _ = append_many_bytes(
                    template_bytes=tpl_file.getvalue(),
                    rows_to_add=rows,
                    template_name=tpl_file.name,
                    sheet_name=SHEET_NAME,
                    allow_same_day_multi=False
                )
                # è‹¥èƒ½èµ°åˆ°é€™è£¡ï¼Œä»£è¡¨æ²’æœ‰ä»»ä½•é‡è¤‡ï¼Œç›´æ¥æ­£å¼åŸ·è¡Œï¼ˆé€™æ¬¡æ‰çœŸçš„ç”¢ç”Ÿè¼¸å‡ºï¼‰
                last_date_added, out_bytes, reorder_info = append_many_bytes(
                    template_bytes=tpl_file.getvalue(),
                    rows_to_add=rows,
                    template_name=tpl_file.name,
                    sheet_name=SHEET_NAME,
                    allow_same_day_multi=True,  # æ²’æœ‰é‡è¤‡ï¼Œè¨­ True/False éƒ½å¯
                    same_day_dates_confirmed=set()
                )

                # æª”åä»¥ç•¶ä¸‹å°åŒ—æ™‚é–“ç‚ºæº–
                now = datetime.now(TZ) if TZ else datetime.now()
                dstr = now.strftime("%Y%m%d")
                hhmm = now.strftime("%H%M")
                prefix = f"{FIXED_BASE}-{dstr}-{hhmm}-"
                n = st.session_state.seq.get(prefix, 0) + 1
                st.session_state.seq[prefix] = n
                out_name = f"{prefix}{n:03d}.xlsx"

                st.session_state.last_result = {
                    "out_name": out_name,
                    "out_bytes": out_bytes,
                    "last_date_added": last_date_added,
                    "generated_at": f"{dstr} {hhmm}",
                }
                st.session_state.last_reorder_info = reorder_info

                st.success(f"å·²ç”¢ç”Ÿï¼š**{out_name}**ï¼ˆè«‹å¾€ä¸‹æ»‘çœ‹ä¸‹è¼‰éˆ•èˆ‡æé†’ï¼‰")

            except Exception as e:
                # å¦‚æœæ˜¯ã€ŒåŒæ—¥å¤šç­†ã€è¢«æ“‹ä¸‹ï¼Œé€²å…¥äº’å‹•ç¢ºèªæµç¨‹
                msg = str(e)
                if "åµæ¸¬åˆ°åŒæ—¥å¤šç­†è³‡æ–™" in msg:
                    # è§£æéœ€è¦ä½¿ç”¨è€…ç¢ºèªçš„æ—¥æœŸæ¸…å–®ï¼ˆå¯èƒ½åŒ…å«å…©ç¨®ä¾†æºï¼‰
                    # å¾è¨Šæ¯æŠ½å‡º YYYYMMDD
                    dup_dates = sorted(set(re.findall(r"\b(\d{8})\b", msg)))
                    if not dup_dates:
                        st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
                    else:
                        st.session_state.pending_dups = {
                            "tpl_name": tpl_file.name,
                            "tpl_bytes": tpl_file.getvalue(),
                            "rows": rows,
                            "dup_dates": dup_dates,
                        }
                        st.session_state.last_result = None
                        st.session_state.last_reorder_info = None
                        st.warning("åµæ¸¬åˆ°åŒæ—¥å¤šç­†è³‡æ–™ï¼Œè«‹æ–¼ä¸‹æ–¹ç¢ºèªæ˜¯å¦å…è¨±ã€‚")
                else:
                    st.session_state.last_result = None
                    st.session_state.last_reorder_info = None
                    st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

# ---- ã€ŒåŒæ—¥å¤šç­†ã€äº’å‹•å€ï¼ˆåœ¨è¡¨å–®å¤–ï¼‰----
if st.session_state.pending_dups:
    st.markdown("---")
    st.subheader("âš ï¸ åµæ¸¬åˆ°åŒæ—¥å¤šç­†è³‡æ–™")
    pd = st.session_state.pending_dups
    with st.expander("æŸ¥çœ‹é‡è¤‡æ—¥æœŸï¼ˆæœ¬æ¬¡è¼¸å…¥å½¼æ­¤æˆ–èˆ‡ç¯„æœ¬é‡è¤‡ï¼‰", expanded=True):
        st.write(", ".join(pd["dup_dates"]))

    c1, c2 = st.columns([1, 1])
    with c1:
        if st.button("âœ… æ˜¯ï¼Œæˆ‘ç¢ºèªæ­¤ç­‰æ—¥æœŸå¯æœ‰å¤šç­†ç´€éŒ„ï¼ˆå°‡æ¨™ç¤º -1/-2/...ï¼‰", type="primary", use_container_width=True):
            try:
                last_date_added, out_bytes, reorder_info = append_many_bytes(
                    template_bytes=pd["tpl_bytes"],
                    rows_to_add=pd["rows"],
                    template_name=pd["tpl_name"],
                    sheet_name=SHEET_NAME,
                    allow_same_day_multi=True,
                    same_day_dates_confirmed=set(pd["dup_dates"])
                )
                now = datetime.now(TZ) if TZ else datetime.now()
                dstr = now.strftime("%Y%m%d")
                hhmm = now.strftime("%H%M")
                prefix = f"{FIXED_BASE}-{dstr}-{hhmm}-"
                n = st.session_state.seq.get(prefix, 0) + 1
                st.session_state.seq[prefix] = n
                out_name = f"{prefix}{n:03d}.xlsx"

                st.session_state.last_result = {
                    "out_name": out_name,
                    "out_bytes": out_bytes,
                    "last_date_added": last_date_added,
                    "generated_at": f"{dstr} {hhmm}",
                }
                st.session_state.last_reorder_info = reorder_info
                st.session_state.pending_dups = None
                st.success("å·²å…è¨±åŒæ—¥å¤šç­†ï¼Œä¸¦å®Œæˆè¼¸å‡ºã€‚è«‹å¾€ä¸‹æ»‘ä¸‹è¼‰ã€‚")
            except Exception as e:
                st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

    with c2:
        if st.button("âŒ å¦ï¼Œå–æ¶ˆæ­¤æ¬¡è¼¸å…¥", use_container_width=True):
            st.session_state.pending_dups = None
            st.info("å·²å–æ¶ˆæ­¤æ¬¡è¼¸å…¥ã€‚")

# ---- è¡¨å–®å¤–ï¼šä¸‹è¼‰èˆ‡æé†’ ----
if st.session_state.last_result:
    out_name = st.session_state.last_result["out_name"]
    out_bytes = st.session_state.last_result["out_bytes"]
    last_date_added = st.session_state.last_result["last_date_added"]
    generated_at = st.session_state.last_result["generated_at"]

    st.markdown("---")
    st.subheader("â‘¢ ä¸‹è¼‰çµæœ")
    st.success(f"å·²ç”¢ç”Ÿï¼š**{out_name}**")
    st.download_button(
        label="â¬‡ï¸ ä¸‹è¼‰æª”æ¡ˆ",
        data=out_bytes,
        file_name=out_name,
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        use_container_width=True,
    )
    st.info(f"ğŸ“Œ æœ¬æ¬¡å¯¦éš›å¯«å…¥çš„æœ€å¾Œä¸€ç­†æ—¥æœŸï¼ˆæ’åºå¾Œï¼‰ï¼š**{last_date_added}**ï½œç”¢ç”Ÿæ™‚é–“ï¼ˆå°åŒ—ï¼‰ï¼š**{generated_at}**")

    info = st.session_state.last_reorder_info or {}
    if info.get("was_reordered"):
        st.warning("åµæ¸¬åˆ°è¼¸å…¥æ—¥æœŸé †åºèˆ‡æ™‚é–“é †åºä¸ä¸€è‡´ï¼Œå·²è‡ªå‹•ä¾æ™‚é–“æ’åºå†å¯«å…¥ã€‚", icon="âš ï¸")
        with st.expander("æŸ¥çœ‹åŸè¼¸å…¥é †åº vs æ’åºå¾Œé †åº"):
            st.write("åŸè¼¸å…¥é †åºï¼š", ", ".join(info.get("original_order", [])) or "ï¼ˆç„¡ï¼‰")
            st.write("æ’åºå¾Œé †åºï¼š", ", ".join(info.get("sorted_order", [])) or "ï¼ˆç„¡ï¼‰")

    wb_last_date = info.get("wb_last_date")
    if info.get("has_earlier_than_wb"):
        st.warning(
            f"æœ¬æ¬¡è¼¸å…¥ä¸­åŒ…å«æ—©æ–¼ç¯„æœ¬æœ€å¾Œæ—¥æœŸï¼ˆ{wb_last_date or 'æœªçŸ¥'}ï¼‰çš„ç´€éŒ„ã€‚"
            " æ–°è³‡æ–™æ˜¯è¿½åŠ åœ¨æª”å°¾ï¼Œé›–å·²å°æœ¬æ¬¡è¼¸å…¥æ’åºï¼Œä»å¯èƒ½èˆ‡æª”å…§æ—¢æœ‰è³‡æ–™çš„æ™‚åºä¸é€£çºŒï¼Œè«‹ç•™æ„ã€‚",
            icon="ğŸ•’"
        )

    confirmed_dates = info.get("confirmed_dates") or []
    if confirmed_dates:
        st.info("ä»¥ä¸‹æ—¥æœŸå·²ä¾åºåŠ ä¸Š -1 / -2 / ... æ¨™ç¤ºï¼š " + ", ".join(confirmed_dates))

